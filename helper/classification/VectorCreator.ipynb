{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eb793fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#Change path specificly to your directories\n",
    "sys.path.insert(1, '/home/codahead/Fishial/FishialReaserch')\n",
    "                \n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.optim import Optimizer, SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.neighbors import KDTree\n",
    "                \n",
    "from module.classification_package.src.model import EmbeddingModel, Backbone, Model\n",
    "from module.classification_package.src.dataset import FishialDataset\n",
    "from module.classification_package.src.dataset import BalancedBatchSampler\n",
    "from module.classification_package.src.utils import read_json, setup_logger, find_device\n",
    "from module.classification_package.src.loss_functions import TripletLoss, QuadrupletLoss\n",
    "from module.classification_package.src.eval import evaluate\n",
    "from module.classification_package.src.utils import save_checkpoint\n",
    "from module.classification_package.src.utils import NewPad\n",
    "                \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn.metrics.pairwise\n",
    "import scipy.spatial.distance\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "\n",
    "np.set_printoptions(precision=20)\n",
    "torch.set_printoptions(precision=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8f5ff3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embedding_model): EmbeddingModel(\n",
       "    (backbone): Backbone(\n",
       "      (resnet): ResNet(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (fc): Identity()\n",
       "      )\n",
       "    )\n",
       "    (embeddings): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (softmax): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def image_loader(loader, image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = loader(image).float()\n",
    "    image = torch.tensor(image, requires_grad=True)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    NewPad(),\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "model = init_model(QuadrupletLoss(), \"../ckpt_0.0_0.915_194.ckpt\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2170f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = transforms.Compose([\n",
    "            NewPad(),\n",
    "            transforms.Resize([224, 224]),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "data_set_train = FishialDataset(\n",
    "        json_path=\"../dataset/data_train.json\",\n",
    "        root_folder=\"../dataset\",\n",
    "        transform=loader\n",
    "    )\n",
    "\n",
    "data_set_val = FishialDataset(\n",
    "        json_path=\"../dataset/data_test.json\",\n",
    "        root_folder=\"../dataset\",\n",
    "        transform=loader\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2cffeb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 10000\r"
     ]
    }
   ],
   "source": [
    "path_data_of_embeddings = '../data_main.json'\n",
    "data_main = copy.deepcopy(data_set_train.library_name)\n",
    "start_time = time.time()\n",
    "for i in range(len(data_set_train)):\n",
    "    print(\"Train: {}\".format(len(data_set_train) - i), end=\"\\r\")\n",
    "    output = model.embedding_model(data_set_train[i][0].unsqueeze(0)).detach().numpy()\n",
    "    converted_list = list([str(sd) for sd in output[0]])\n",
    "    if \"vectors\" in data_main[int(data_set_train[i][1])]:\n",
    "        data_main[int(data_set_train[i][1])][\"vectors\"].append(converted_list)\n",
    "    else:\n",
    "        data_main[int(data_set_train[i][1])].update({\"vectors\": [converted_list]})\n",
    "    start_time = time.time()\n",
    "\n",
    "for i in range(len(data_set_val)):\n",
    "    print(\"Test: {}\".format(len(data_set_val) - i), end=\"\\r\")\n",
    "    output = model.embedding_model(data_set_val[i][0].unsqueeze(0)).detach().numpy()\n",
    "    converted_list = list([str(sd) for sd in output[0]])\n",
    "    if \"vectors\" in data_main[int(data_set_val[i][1])]:\n",
    "        data_main[int(data_set_val[i][1])][\"vectors\"].append(converted_list)\n",
    "    else:\n",
    "        data_main[int(data_set_val[i][1])].update({\"vectors\": [converted_list]})\n",
    "\n",
    "with open(path_data_of_embeddings, 'w') as f:\n",
    "    json.dump(data_main, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e90ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_base_of_embed(path):\n",
    "    data = read_json(path)\n",
    "    for i in data:\n",
    "        for z in range(len(data[i][\"vectors\"])):\n",
    "            data[i][\"vectors\"][z] = [float(val) for val in data[i][\"vectors\"][z]]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbaf6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_main = get_data_base_of_embed(path_data_of_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "D2GO",
   "language": "python",
   "name": "d2go"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
